#!/usr/bin/env python3
"""
Excel Handler Module - Clean Version
Enhanced Excel file processing for BigQuery validation scenarios with business logic parsing.
"""

import pandas as pd
import streamlit as st
from datetime import datetime
import logging
from typing import Dict, List, Any, Tuple, Optional
import re

# Import the SQL generator and BigQuery client
from sql_generator import (
    create_transformation_validation_sql,
    convert_business_logic_to_safe_sql,
    create_enhanced_transformation_sql,
    create_reference_table_validation_sql
)
from dynamic_column_discovery import get_dynamic_column_manager
from bigquery_client import execute_custom_query

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def generate_scenarios_from_excel(df: pd.DataFrame, project_id: str = None, dataset_id: str = None) -> List[Dict[str, Any]]:
    """Generate validation scenarios from Excel data with enhanced parsing."""
    scenarios = []
    
    try:
        # Use the provided DataFrame directly
        main_sheet = df
        
        if main_sheet is None or main_sheet.empty:
            logger.warning("No valid data found in Excel sheet")
            return scenarios
        
        # Clean column names
        main_sheet.columns = main_sheet.columns.str.strip()
        
        # Process each row as a scenario
        for index, row in main_sheet.iterrows():
            try:
                # Skip empty rows
                if pd.isna(row.get('Scenario_Name', '')) or str(row.get('Scenario_Name', '')).strip() == '':
                    continue
                
                # Extract basic scenario information
                scenario = {
                    'scenario_name': str(row.get('Scenario_Name', f'Scenario_{index+1}')).strip(),
                    'source_table': str(row.get('Source_Table', '')).strip(),
                    'target_table': str(row.get('Target_Table', '')).strip(),
                    'derivation_logic': str(row.get('Derivation_Logic', '')).strip(),
                    'validation_type': str(row.get('Validation_Type', 'Transformation')).strip(),
                    'business_rule': str(row.get('Business_Rule', '')).strip(),
                    
                    # Dataset IDs
                    'source_dataset_id': str(row.get('Source_Dataset_Id', dataset_id or 'banking_sample_data')).strip(),
                    'target_dataset_id': str(row.get('Target_Dataset_Id', dataset_id or 'banking_sample_data')).strip(),
                    
                    # Join keys
                    'source_join_key': str(row.get('Source_Join_Key', '')).strip(),
                    'target_join_key': str(row.get('Target_Join_Key', '')).strip(),
                    'target_column': str(row.get('Target_Column', '')).strip(),
                    
                    # Enhanced reference table support
                    'reference_table': str(row.get('Reference_Table', '')).strip(),
                    'reference_join_key': str(row.get('Reference_Join_Key', '')).strip(),
                    'reference_lookup_column': str(row.get('Reference_Lookup_Column', '')).strip(),
                    'reference_return_column': str(row.get('Reference_Return_Column', '')).strip(),
                    'business_conditions': str(row.get('Business_Conditions', '')).strip(),
                    'hardcoded_values': str(row.get('Hardcoded_Values', '')).strip(),
                    
                    # Status
                    'status': 'Ready',
                    'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                
                # Only add if we have essential data
                if scenario['source_table'] and scenario['derivation_logic']:
                    scenarios.append(scenario)
                    logger.info(f"Generated scenario: {scenario['scenario_name']}")
                
            except Exception as e:
                logger.error(f"Error processing row {index}: {str(e)}")
                continue
                
    except Exception as e:
        logger.error(f"Error generating scenarios from Excel: {str(e)}")
        st.error(f"‚ùå Error processing Excel file: {str(e)}")
    
    return scenarios


def process_excel_file(uploaded_file):
    """Process uploaded Excel file and return data."""
    try:
        # Read Excel file
        excel_data = pd.read_excel(uploaded_file, sheet_name=None)
        return excel_data, None
    except Exception as e:
        return None, f"‚ùå Error reading Excel file: {str(e)}"


def execute_all_excel_scenarios():
    """Execute all transformation validation scenarios generated from Excel."""
    if 'excel_scenarios' not in st.session_state or not st.session_state['excel_scenarios']:
        st.error("‚ùå No scenarios available to execute.")
        return
    
    # Check if project_id is configured
    project_id = st.session_state.get('project_id')
    if not project_id:
        st.error("‚ùå **Google Cloud Project ID not configured!**")
        st.error("**Table is not accessible.** Please configure your project ID in the settings.")
        st.info("üí° Go to Settings ‚Üí Set your Google Cloud Project ID in the sidebar")
        return
    
    scenarios = st.session_state['excel_scenarios']
    results = []
    
    # Progress tracking
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, scenario in enumerate(scenarios):
        try:
            status_text.text(f"üîÑ Executing scenario {i+1}/{len(scenarios)}: {scenario['scenario_name']}")
            
            # Generate SQL based on scenario type
            if scenario.get('reference_table') and str(scenario.get('reference_table')).lower() not in ['nan', 'none', '']:
                # Reference table validation
                sql_query = create_reference_table_validation_sql(
                    source_table=scenario['source_table'],
                    target_table=scenario.get('target_table', scenario['source_table']),
                    source_join_key=scenario.get('source_join_key', 'id'),
                    target_join_key=scenario.get('target_join_key', 'id'),
                    target_column=scenario['target_column'],
                    derivation_logic=scenario['derivation_logic'],
                    reference_table=scenario['reference_table'],
                    reference_join_key=scenario.get('reference_join_key', 'id'),
                    reference_lookup_column=scenario.get('reference_lookup_column', 'value'),
                    reference_return_column=scenario.get('reference_return_column', 'value'),
                    business_conditions=scenario.get('business_conditions', ''),
                    hardcoded_values=scenario.get('hardcoded_values', ''),
                    project_id=project_id,
                    source_dataset_id=scenario.get('source_dataset_id', 'banking_sample_data'),
                    target_dataset_id=scenario.get('target_dataset_id', 'banking_sample_data')
                )
            elif scenario.get('target_table') and str(scenario.get('target_table')).lower() not in ['nan', 'none', '']:
                # Enhanced transformation validation
                sql_query = create_enhanced_transformation_sql(
                    source_table=scenario['source_table'],
                    target_table=scenario['target_table'],
                    source_join_key=scenario.get('source_join_key', 'id'),
                    target_join_key=scenario.get('target_join_key', 'id'),
                    target_column=scenario['target_column'],
                    derivation_logic=scenario['derivation_logic'],
                    project_id=project_id,
                    source_dataset_id=scenario.get('source_dataset_id', 'banking_sample_data'),
                    target_dataset_id=scenario.get('target_dataset_id', 'banking_sample_data')
                )
            else:
                # Basic transformation validation
                column_manager = get_dynamic_column_manager(project_id, 'banking_sample_data')
                sql_query = create_transformation_validation_sql(
                    source_table=scenario['source_table'],
                    target_table=scenario.get('target_table', scenario['source_table']),
                    source_join_key=scenario.get('source_join_key', 'id'),
                    target_join_key=scenario.get('target_join_key', 'id'),
                    target_column=scenario.get('target_column', 'derived_value'),
                    derivation_logic=scenario['derivation_logic'],
                    project_id=project_id,
                    source_dataset_id=scenario.get('source_dataset_id', 'banking_sample_data'),
                    target_dataset_id=scenario.get('target_dataset_id', 'banking_sample_data'),
                    column_manager=column_manager
                )
            
            # Execute the query
            if sql_query:
                query_result, message = execute_custom_query(sql_query, scenario['scenario_name'])
                
                if query_result and query_result['status'] == 'success':
                    df = query_result['data']
                    
                    if df is not None and not df.empty:
                        # Handle new detailed format with SUMMARY, FAILED_RECORD, PASSED_RECORD
                        if 'record_type' in df.columns:
                            # New detailed format - extract summary information
                            summary_row = df[df['record_type'] == 'SUMMARY']
                            failed_records = df[df['record_type'] == 'FAILED_RECORD']
                            passed_records = df[df['record_type'] == 'PASSED_RECORD']
                            
                            if not summary_row.empty:
                                summary_status = summary_row.iloc[0]['validation_result']
                                summary_details = summary_row.iloc[0]['validation_details']
                                
                                # Parse counts from summary details
                                import re
                                total_match = re.search(r'Total: (\d+)', summary_details)
                                passed_match = re.search(r'Passed: (\d+)', summary_details)
                                failed_match = re.search(r'Failed: (\d+)', summary_details)
                                
                                total_count = int(total_match.group(1)) if total_match else len(df)
                                passed_count = int(passed_match.group(1)) if passed_match else len(passed_records)
                                failed_count = int(failed_match.group(1)) if failed_match else len(failed_records)
                                
                                status = 'PASS' if summary_status == 'OVERALL_PASS' else 'FAIL'
                            else:
                                # Fallback if no summary row
                                total_count = len(df)
                                passed_count = len(passed_records)
                                failed_count = len(failed_records)
                                status = 'PASS' if failed_count == 0 else 'FAIL'
                                
                        # Handle legacy format with validation_status column
                        elif 'validation_status' in df.columns:
                            # Old format with validation_status column
                            status = df.iloc[0]['validation_status']
                            passed_count = df.iloc[0].get('row_count', 1) if status == 'PASS' else 0
                            total_count = df.iloc[0].get('row_count', 1)
                        elif 'validation_result' in df.columns:
                            # Old format with validation_result column
                            passed_count = len(df[df['validation_result'] == 'PASS'])
                            total_count = len(df)
                            status = 'PASS' if passed_count == total_count else 'FAIL'
                        else:
                            # If no validation columns, check if we have any rows (failures)
                            status = 'FAIL' if len(df) > 0 else 'PASS'
                            passed_count = 0 if len(df) > 0 else 1
                            total_count = max(1, len(df))
                        
                        results.append({
                            'scenario_name': scenario['scenario_name'],
                            'status': status,
                            'total_rows': total_count,
                            'pass_rows': passed_count,
                            'fail_rows': total_count - passed_count,
                            'total_records': total_count,  # Keep for backward compatibility
                            'passed_records': passed_count,  # Keep for backward compatibility
                            'sql_query': sql_query,
                            'result_data': df,
                            'execution_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                            'timestamp': datetime.now()
                        })
                    else:
                        results.append({
                            'scenario_name': scenario['scenario_name'],
                            'status': 'PASS',  # No data usually means no issues found
                            'total_rows': 0,
                            'pass_rows': 0,
                            'fail_rows': 0,
                            'total_records': 0,  # Keep for backward compatibility
                            'passed_records': 0,  # Keep for backward compatibility
                            'sql_query': sql_query,
                            'result_data': pd.DataFrame(),
                            'execution_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                            'timestamp': datetime.now()
                        })
                else:
                    # Query execution failed
                    error_msg = query_result.get('error', 'Unknown error') if query_result else 'Query execution failed'
                    st.write(f"‚ùå Error executing query for scenario {scenario['scenario_name']}: {error_msg}")
                    results.append({
                        'scenario_name': scenario['scenario_name'],
                        'status': 'ERROR',
                        'total_rows': 0,
                        'pass_rows': 0,
                        'fail_rows': 0,
                        'error_message': error_msg,
                        'sql_query': sql_query,
                        'execution_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                        'timestamp': datetime.now()
                    })
            else:
                results.append({
                    'scenario_name': scenario['scenario_name'],
                    'status': 'ERROR',
                    'total_rows': 0,
                    'pass_rows': 0,
                    'fail_rows': 0,
                    'error_message': 'Failed to generate SQL query',
                    'execution_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'timestamp': datetime.now()
                })
                
        except Exception as e:
            logger.error(f"Error executing scenario {scenario['scenario_name']}: {str(e)}")
            results.append({
                'scenario_name': scenario['scenario_name'],
                'status': 'ERROR',
                'total_rows': 0,
                'pass_rows': 0,
                'fail_rows': 0,
                'error_message': str(e),
                'execution_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'timestamp': datetime.now()
            })
        
        # Update progress
        progress_bar.progress((i + 1) / len(scenarios))
    
    # Store results in session state
    st.session_state['scenario_results'] = results
    
    # Clear progress indicators
    progress_bar.empty()
    status_text.empty()
    
    # Show summary
    passed = len([r for r in results if r['status'] == 'PASS'])
    failed = len([r for r in results if r['status'] == 'FAIL'])
    errors = len([r for r in results if r['status'] == 'ERROR'])
    
    st.success(f"‚úÖ Execution completed! Passed: {passed}, Failed: {failed}, Errors: {errors}")
    
    # Show results table
    if results:
        results_df = pd.DataFrame([
            {
                'Scenario': r['scenario_name'],
                'Status': r['status'],
                'Records': r.get('total_rows', 0),
                'Execution Time': r['execution_time']
            }
            for r in results
        ])
        st.dataframe(results_df, use_container_width=True)


def validate_excel_format(df: pd.DataFrame) -> Tuple[bool, List[str]]:
    """Validate that the Excel file has the required format."""
    required_columns = ['Scenario_Name', 'Source_Table', 'Derivation_Logic']
    optional_columns = ['Target_Table', 'Target_Column', 'Validation_Type', 'Business_Rule']
    
    errors = []
    
    # Check for required columns
    missing_required = [col for col in required_columns if col not in df.columns]
    if missing_required:
        errors.append(f"Missing required columns: {', '.join(missing_required)}")
    
    # Check for empty required fields
    for col in required_columns:
        if col in df.columns:
            empty_count = df[col].isna().sum() + (df[col] == '').sum()
            if empty_count > 0:
                errors.append(f"Column '{col}' has {empty_count} empty values")
    
    return len(errors) == 0, errors


def get_scenario_preview(scenarios: List[Dict[str, Any]]) -> pd.DataFrame:
    """Create a preview DataFrame of scenarios for display."""
    if not scenarios:
        return pd.DataFrame()
    
    preview_data = []
    for scenario in scenarios:
        preview_data.append({
            'Scenario Name': scenario.get('scenario_name', 'N/A'),
            'Source Table': scenario.get('source_table', 'N/A'),
            'Target Table': scenario.get('target_table', 'N/A'),
            'Validation Type': scenario.get('validation_type', 'N/A'),
            'Business Rule': scenario.get('business_rule', 'N/A')[:50] + '...' if len(scenario.get('business_rule', '')) > 50 else scenario.get('business_rule', 'N/A')
        })
    
    return pd.DataFrame(preview_data)


def get_scenario_type(scenario: Dict[str, Any]) -> str:
    """Determine the type of validation scenario."""
    if scenario.get('reference_table') and str(scenario.get('reference_table')).lower() not in ['nan', 'none', '']:
        return 'Reference Table'
    elif scenario.get('target_table') and str(scenario.get('target_table')).lower() not in ['nan', 'none', '']:
        return 'Enhanced Transformation'
    else:
        return 'Basic Transformation'


def generate_sql_for_scenario(scenario: Dict[str, Any], project_id: str = None, dataset_id: str = 'banking_sample_data') -> str:
    """Generate SQL for a specific scenario for preview purposes."""
    
    # Early validation to prevent hanging
    if not scenario:
        return "-- ERROR: No scenario provided"
    
    if not scenario.get('scenario_name'):
        return "-- ERROR: Scenario name is missing"
    
    if not scenario.get('source_table'):
        return "-- ERROR: Source table is missing"
    
    if not scenario.get('derivation_logic'):
        return "-- ERROR: Derivation logic is missing"
    
    # Check if project_id is provided or available in session state
    if project_id is None:
        import streamlit as st
        project_id = st.session_state.get('project_id')
    
    # *** DEBUG: Add detailed project ID debugging ***
    import streamlit as st
    import logging
    logger = logging.getLogger(__name__)
    
    logger.info(f"üîç PROJECT ID DEBUG in generate_sql_for_scenario:")
    logger.info(f"  - project_id parameter: '{project_id}' (type: {type(project_id)})")
    logger.info(f"  - session_state project_id: '{st.session_state.get('project_id')}' (type: {type(st.session_state.get('project_id'))})")
    logger.info(f"  - session_state keys: {list(st.session_state.keys())}")
    
    # Show debug info in Streamlit as well
    st.write("üîç **PROJECT ID DEBUG in generate_sql_for_scenario:**")
    st.write(f"- Function parameter `project_id`: `{repr(project_id)}` (type: {type(project_id).__name__})")
    st.write(f"- Session state `project_id`: `{repr(st.session_state.get('project_id'))}` (type: {type(st.session_state.get('project_id')).__name__})")
    st.write(f"- Boolean check `not project_id`: {not project_id}")
    st.write(f"- Boolean check `project_id is None`: {project_id is None}")
    st.write(f"- Boolean check `project_id == ''`: {project_id == ''}")
        
    if not project_id:
        st.error("‚ùå **Project ID validation failed at line 409 in excel_handler.py**")
        return """-- ‚ùå ERROR: Google Cloud Project ID not configured!
-- Table is not accessible. Please configure your project ID in the settings.
-- Go to Settings ‚Üí Set your Google Cloud Project ID in the sidebar

-- Cannot generate SQL query without valid project ID
SELECT 'ERROR: Project ID not configured' as error_message;"""
    
    try:
        # Add logging to help debug
        import logging
        logger = logging.getLogger(__name__)
        logger.info(f"Starting SQL generation for scenario: {scenario.get('scenario_name')}")
        
        # Generate SQL based on scenario type with timeout protection
        sql_query = None
        scenario_type = None
        
        if scenario.get('reference_table') and str(scenario.get('reference_table')).lower() not in ['nan', 'none', '']:
            scenario_type = "Reference Table"
            logger.info(f"Generating reference table validation SQL")
            # Reference table validation
            sql_query = create_reference_table_validation_sql(
                source_table=scenario['source_table'],
                target_table=scenario.get('target_table', scenario['source_table']),
                source_join_key=scenario.get('source_join_key', 'id'),
                target_join_key=scenario.get('target_join_key', 'id'),
                target_column=scenario['target_column'],
                derivation_logic=scenario['derivation_logic'],
                reference_table=scenario['reference_table'],
                reference_join_key=scenario.get('reference_join_key', 'id'),
                reference_lookup_column=scenario.get('reference_lookup_column', 'value'),
                reference_return_column=scenario.get('reference_return_column', 'value'),
                business_conditions=scenario.get('business_conditions', ''),
                hardcoded_values=scenario.get('hardcoded_values', ''),
                project_id=project_id,
                source_dataset_id=scenario.get('source_dataset_id', dataset_id),
                target_dataset_id=scenario.get('target_dataset_id', dataset_id)
            )
        elif scenario.get('target_table') and str(scenario.get('target_table')).lower() not in ['nan', 'none', '']:
            scenario_type = "Enhanced Transformation"
            logger.info(f"Generating enhanced transformation validation SQL")
            # Enhanced transformation validation
            sql_query = create_enhanced_transformation_sql(
                source_table=scenario['source_table'],
                target_table=scenario['target_table'],
                source_join_key=scenario.get('source_join_key', 'id'),
                target_join_key=scenario.get('target_join_key', 'id'),
                target_column=scenario['target_column'],
                derivation_logic=scenario['derivation_logic'],
                project_id=project_id,
                source_dataset_id=scenario.get('source_dataset_id', dataset_id),
                target_dataset_id=scenario.get('target_dataset_id', dataset_id)
            )
        else:
            scenario_type = "Basic Transformation"
            logger.info(f"Generating basic transformation validation SQL")
            # Basic transformation validation
            column_manager = get_dynamic_column_manager(project_id, dataset_id)
            sql_query = create_transformation_validation_sql(
                source_table=scenario['source_table'],
                target_table=scenario.get('target_table', scenario['source_table']),
                source_join_key=scenario.get('source_join_key', 'id'),
                target_join_key=scenario.get('target_join_key', 'id'),
                target_column=scenario.get('target_column', 'derived_value'),
                derivation_logic=scenario['derivation_logic'],
                project_id=project_id,
                source_dataset_id=scenario.get('source_dataset_id', dataset_id),
                target_dataset_id=scenario.get('target_dataset_id', dataset_id),
                column_manager=column_manager
            )
        
        logger.info(f"SQL generation completed for {scenario_type} scenario")
        
        # Validate the generated SQL
        if not sql_query:
            return f"""-- ‚ùå ERROR: {scenario_type} SQL generation returned empty result
-- Scenario: {scenario.get('scenario_name')}
-- Please check the scenario configuration

SELECT 'Empty SQL result' as error_message;"""
        
        if len(sql_query.strip()) < 10:
            return f"""-- ‚ùå ERROR: {scenario_type} SQL generation returned invalid result
-- Scenario: {scenario.get('scenario_name')}  
-- Result was too short: {sql_query}

SELECT 'Invalid SQL result' as error_message;"""
        
        return sql_query
        
    except Exception as e:
        error_msg = str(e)
        logger.error(f"SQL generation failed for scenario {scenario.get('scenario_name')}: {error_msg}")
        return f"""-- ‚ùå ERROR: Failed to generate SQL query
-- Scenario: {scenario.get('scenario_name', 'Unknown')}
-- Error details: {error_msg}
-- Please check your scenario configuration and project settings

SELECT 'SQL generation error: {error_msg}' as error_message;"""
